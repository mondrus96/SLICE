% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/slice.R
\name{slice}
\alias{slice}
\title{SLICE estimator}
\usage{
slice(Sigma, rho, r, Sest = "glasso", tol = 0.001, maxiter = 100)
}
\arguments{
\item{Sigma}{A matrix. The input covariance matrix.}

\item{rho}{A numeric. Regularization parameter for sparse estimator.}

\item{r}{An integer. Rank for latent component.}

\item{Sest}{A character string. Type of sparse estimator to use, default =
\code{"glasso"}(Friedman et al, 2008), other choices include \code{"gscad"}
(Fan et al., 2009), \code{"clime"}(Cai et al., 2011), and
\code{"huge_glasso"} (Zhao et al., 2012).}

\item{tol}{A numeric. Tolerance for algorithm, default = 1e-3.}

\item{maxiter}{An integer. Maximum number of iterations, default = 100.}
}
\value{
An S3 class \code{slice} object with:
\item{S}{A matrix corresoponding to the estimated sparse component.}
\item{L}{A matrix corresoponding to the estimated latent component.}
\item{rho}{A numeric of the regularization
parameter used for the sparse component.}
\item{r}{An integer of the rank used for the latent component.}
\item{misc}{contains additional outputs
related to the convergence of the algorithm.}
}
\description{
This function implements sparse + low-rank inverse covariance estimation (SLICE).
}
\details{
Given sample covariance \eqn{\boldsymbol{\tilde{\Sigma}}} the
objective, for the L1 penalized variant, is to find \eqn{\boldsymbol{
\hat{S}}} and \eqn{\boldsymbol{\hat{L}}} which minimize the following function:
\deqn{
\underbrace{- \mathcal{L}(\boldsymbol{\hat{S}};(\boldsymbol{\tilde{\Sigma}}
^{-1} - \boldsymbol{\hat{L}})^{-1}) + \rho \|\boldsymbol{\hat{S}}\|_1}_{
\text{penalized negative log likelihood}} + \underbrace{\|\boldsymbol{\tilde
{\Sigma}}(\boldsymbol{\hat{S}} + \boldsymbol{\hat{L}}) - \boldsymbol{I}
\|_F^2}_{\text{covariance fidelity}} \\
\text{s.t. } \mathcal{R}(\boldsymbol{\hat{L}}) = r, \ \text{where } 0 < r < p
}
where \eqn{\rho} and \eqn{r} are regularization parameters for the sparse
and latent components, respectively.
}
\examples{
set.seed(123)
p <- 100 # Number of nodes

S <- outer(1:p, 1:p,
        function(i, j) 1 * exp(-0.5 * abs(i - j))) # Exponential decay
S[S < 0.01] <- 0
perm <- sample(p) # Permute
S <- S[perm, perm]

r <- 4 # Rank of latent
probs <- runif(r)
probs <- probs / sum(probs)
Z <- matrix(0, p, r)
indices <- sample(1:r, p, replace = TRUE, prob = probs)
Z[cbind(1:p, indices)] <- 1
L <- Z \%*\% t(Z)

Sigma <- solve(S + L) # Define Sigma

out <- slice(Sigma, 0.01, r) # Run SLICE

out <- slice(Sigma, 0.01, r, Sest = "gscad") # Run SLICE with SCAD
}
\references{
Cai, T., Liu, W., and Luo, X. A constrained l1 minimization
approach to sparse precision matrix estimation. \emph{Journal
of the American Statistical Association}, 106(494):594–607, 2011.

Fan, J., Feng, Y., and Wu, Y. Network exploration via the
adaptive lasso and scad penalties. \emph{The annals of
applied statistics}, 3(2):521, 2009.

Friedman, J., Hastie, T., and Tibshirani, R. Sparse inverse
covariance estimation with the graphical lasso.
\emph{Biostatistics}, 9(3):432–441, 2008.

Zhao, T., Liu, H., Roeder, K., Lafferty, J., and
Wasserman, L. The huge package for high dimensional
undirected graph estimation in r. \emph{The Journal
of Machine Learning Research}, 13(1):1059–1062, 2012.
}
\seealso{
\code{\link{cv.slice}}
}
