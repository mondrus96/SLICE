% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv.slice.R
\name{cv.slice}
\alias{cv.slice}
\title{Cross validation for model selection in SLICE}
\usage{
cv.slice(
  X,
  folds = 3,
  rhos = logseq(1e-05, 0.1, 5),
  rs = 2:6,
  Sest = "glasso",
  tol = 0.001,
  maxiter = 100,
  verbose = TRUE
)
}
\arguments{
\item{X}{A matrix. The input data matrix.}

\item{folds}{A numeric. The number of folds to split the data into.}

\item{rhos}{A vector of numerics. Regularization parameter for sparse estimator.}

\item{rs}{A vector of integers. Ranks for latent component.}

\item{Sest}{A character string. Type of sparse estimator to use, default =
\code{"glasso"}(Friedman et al, 2008), other choices include \code{"gscad"}
(Fan et al., 2009), \code{"clime"}(Cai et al., 2011), and
\code{"huge_glasso"} (Zhao et al., 2012).}

\item{tol}{A numeric. Tolerance for algorithm, default = 1e-3.}

\item{maxiter}{An integer. Maximum number of iterations, default = 100.}

\item{verbose}{A logical. Whether to print progress, default = TRUE}
}
\value{
An S3 class \code{cv.slice} object with:
\item{cvmat}{A matrix of log likelihood values for each combination of
rho and r.}
\item{maxlogL}{The maximum log likehood value.}
\item{rho}{A numeric of the regularization parameter corresponding to the
highest likelihood.}
\item{r}{An integer of the rank corresponding to the highest likelihood.}
}
\description{
This function implements cross validation for SLICE
}
\details{
This function implements a grid search over all combinations of
\eqn{\rho} and \eqn{r}, and finds the best combination as determined by
log likelihood.
}
\examples{
# A trivial example
set.seed(123)
p <- 10
n <- 100
X <- matrix(rnorm(n*p), nrow=n)

# Run CV for SLICE
cv.out <- cv.slice(X, folds = 2, rhos = c(0.1, 0.2), rs = c(2, 3))
}
\references{
Cai, T., Liu, W., and Luo, X. A constrained l1 minimization approach to sparse precision matrix estimation. \emph{Journal of the American Statistical Association}, 106(494):594–607, 2011.

Fan, J., Feng, Y., and Wu, Y. Network exploration via the adaptive lasso and scad penalties. \emph{The annals of applied statistics}, 3(2):521, 2009.

Friedman, J., Hastie, T., and Tibshirani, R. Sparse inverse covariance estimation with the graphical lasso. \emph{Biostatistics}, 9(3):432–441, 2008.

Zhao, T., Liu, H., Roeder, K., Lafferty, J., and Wasserman, L. The huge package for high dimensional undirected graph estimation in r. \emph{The Journal of Machine Learning Research}, 13(1):1059–1062, 2012.
}
\seealso{
\code{\link{slice}}
}
